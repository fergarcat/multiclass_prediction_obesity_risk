{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Libraries and Load Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from pipeline_utils import CustomRowTransformer\n",
    "from dotenv import load_dotenv\n",
    "from benchmarks import ml_benchmarks, custom_ml_benchmarks, optimize_xgboost\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import os\n",
    "load_dotenv()\n",
    "ML_PREPROC_FILENAME = os.getenv(\"ML_PREPROC_FILENAME\")\n",
    "CSV_FOLDER = os.getenv(\"CSV_FOLDER\")\n",
    "CSV_TRAIN_FILENAME = os.getenv(\"CSV_TRAIN_FILENAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load Data and Preprocess PKL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV path: c:\\Users\\Fernando\\VSC\\python\\dev\\p7-1\\multi-class_prediction_obesity_risk\\data\\.kaggle\\train.csv\n",
      "Preprocessing pipeline path: c:\\Users\\Fernando\\VSC\\python\\dev\\p7-1\\multi-class_prediction_obesity_risk\\data\\modeling\\pkl\\preprocessing_pipeline.pkl\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "csv_path = os.path.join(parent_dir, \".kaggle\", \"train.csv\")\n",
    "print(f'CSV path: {csv_path}')\n",
    "pre_pkl_path = os.path.join(parent_dir, \"modeling\", \"pkl\", ML_PREPROC_FILENAME)\n",
    "print(f'Preprocessing pipeline path: {pre_pkl_path}')\n",
    "\n",
    "# Load raw data and preprocessing pipeline\n",
    "df = pd.read_csv(csv_path)\n",
    "preprocessing_pipeline = joblib.load(pre_pkl_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. APPLY PIPELINE AND SPLIT FEATURES AND TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing\n",
    "df_prepared = preprocessing_pipeline.transform(df)   \n",
    "\n",
    "# Separate features and target\n",
    "X = df_prepared.drop(columns=[\"NObeyesdad\", \"SMOKE\",\"MTRANS\",\"id\"])\n",
    "y = df_prepared[\"NObeyesdad\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. OBTAIN MODELS BENCHMARK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fernando\\VSC\\python\\dev\\p7-1\\multi-class_prediction_obesity_risk\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:25:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004026 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1120\n",
      "[LightGBM] [Info] Number of data points in the train set: 16606, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score -2.107657\n",
      "[LightGBM] [Info] Start training from score -1.907572\n",
      "[LightGBM] [Info] Start training from score -1.964755\n",
      "[LightGBM] [Info] Start training from score -1.855022\n",
      "[LightGBM] [Info] Start training from score -1.635117\n",
      "[LightGBM] [Info] Start training from score -2.146046\n",
      "[LightGBM] [Info] Start training from score -2.107657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fernando\\VSC\\python\\dev\\p7-1\\multi-class_prediction_obesity_risk\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Fernando\\VSC\\python\\dev\\p7-1\\multi-class_prediction_obesity_risk\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+--------------------+--------------------+--------------------+--------------------+----------------+-------------+\n",
      "|        Model        |      Accuracy      |     Precision      |       Recall       |      F1-Score      | Train Time (s) | Overfitting |\n",
      "+---------------------+--------------------+--------------------+--------------------+--------------------+----------------+-------------+\n",
      "|       XGBoost       | 0.9072736030828517 | 0.9070431550288031 | 0.9072736030828517 | 0.9070520800655331 |     2.4346     |   0.0769    |\n",
      "|      CatBoost       | 0.9060693641618497 | 0.9055571752237769 | 0.9060693641618497 | 0.9057671655185464 |    35.4323     |   0.0483    |\n",
      "|      LightGBM       | 0.9051059730250481 | 0.904767060264294  | 0.9051059730250481 | 0.904858615859683  |     4.7564     |   0.0711    |\n",
      "|    Random Forest    | 0.9036608863198459 | 0.9029543954604532 | 0.9036608863198459 | 0.9031310719897029 |     3.8831     |   0.0962    |\n",
      "|      SVM (RBF)      | 0.8831888246628131 | 0.8822304830819414 | 0.8831888246628131 | 0.8826031033709307 |     5.1034     |   0.0137    |\n",
      "|    SVM (Linear)     | 0.8697013487475915 | 0.8684212142624876 | 0.8697013487475915 | 0.8687769244560287 |     5.1625     |   -0.0029   |\n",
      "| Logistic Regression | 0.8639210019267822 | 0.8623670260449364 | 0.8639210019267822 | 0.8628638587796892 |     0.7557     |   -0.0013   |\n",
      "|    Decision Tree    | 0.8407996146435452 | 0.8404083793820208 | 0.8407996146435452 | 0.840379515755937  |     0.1659     |   0.1591    |\n",
      "|         KNN         | 0.7935934489402697 | 0.790630977001732  | 0.7935934489402697 | 0.7907663600653316 |     0.2451     |   0.0574    |\n",
      "|     Naive Bayes     | 0.7755298651252408 | 0.7709755178352045 | 0.7755298651252408 | 0.7691401708487299 |     0.026      |   -0.0024   |\n",
      "+---------------------+--------------------+--------------------+--------------------+--------------------+----------------+-------------+\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Precision",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Recall",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F1-Score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Train Time (s)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Overfitting",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "718b8e73-efff-4546-8fce-275aba2b0cc3",
       "rows": [
        [
         "7",
         "XGBoost",
         "0.9072736030828517",
         "0.9070431550288031",
         "0.9072736030828517",
         "0.9070520800655331",
         "2.4346",
         "0.0769"
        ],
        [
         "9",
         "CatBoost",
         "0.9060693641618497",
         "0.9055571752237769",
         "0.9060693641618497",
         "0.9057671655185464",
         "35.4323",
         "0.0483"
        ],
        [
         "8",
         "LightGBM",
         "0.9051059730250481",
         "0.904767060264294",
         "0.9051059730250481",
         "0.904858615859683",
         "4.7564",
         "0.0711"
        ],
        [
         "2",
         "Random Forest",
         "0.9036608863198459",
         "0.9029543954604532",
         "0.9036608863198459",
         "0.9031310719897029",
         "3.8831",
         "0.0962"
        ],
        [
         "4",
         "SVM (RBF)",
         "0.8831888246628131",
         "0.8822304830819414",
         "0.8831888246628131",
         "0.8826031033709307",
         "5.1034",
         "0.0137"
        ],
        [
         "3",
         "SVM (Linear)",
         "0.8697013487475915",
         "0.8684212142624876",
         "0.8697013487475915",
         "0.8687769244560287",
         "5.1625",
         "-0.0029"
        ],
        [
         "0",
         "Logistic Regression",
         "0.8639210019267822",
         "0.8623670260449364",
         "0.8639210019267822",
         "0.8628638587796892",
         "0.7557",
         "-0.0013"
        ],
        [
         "1",
         "Decision Tree",
         "0.8407996146435452",
         "0.8404083793820208",
         "0.8407996146435452",
         "0.840379515755937",
         "0.1659",
         "0.1591"
        ],
        [
         "6",
         "KNN",
         "0.7935934489402697",
         "0.790630977001732",
         "0.7935934489402697",
         "0.7907663600653316",
         "0.2451",
         "0.0574"
        ],
        [
         "5",
         "Naive Bayes",
         "0.7755298651252408",
         "0.7709755178352045",
         "0.7755298651252408",
         "0.7691401708487299",
         "0.026",
         "-0.0024"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Train Time (s)</th>\n",
       "      <th>Overfitting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.907274</td>\n",
       "      <td>0.907043</td>\n",
       "      <td>0.907274</td>\n",
       "      <td>0.907052</td>\n",
       "      <td>2.4346</td>\n",
       "      <td>0.0769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.906069</td>\n",
       "      <td>0.905557</td>\n",
       "      <td>0.906069</td>\n",
       "      <td>0.905767</td>\n",
       "      <td>35.4323</td>\n",
       "      <td>0.0483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.905106</td>\n",
       "      <td>0.904767</td>\n",
       "      <td>0.905106</td>\n",
       "      <td>0.904859</td>\n",
       "      <td>4.7564</td>\n",
       "      <td>0.0711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.903661</td>\n",
       "      <td>0.902954</td>\n",
       "      <td>0.903661</td>\n",
       "      <td>0.903131</td>\n",
       "      <td>3.8831</td>\n",
       "      <td>0.0962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM (RBF)</td>\n",
       "      <td>0.883189</td>\n",
       "      <td>0.882230</td>\n",
       "      <td>0.883189</td>\n",
       "      <td>0.882603</td>\n",
       "      <td>5.1034</td>\n",
       "      <td>0.0137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM (Linear)</td>\n",
       "      <td>0.869701</td>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.869701</td>\n",
       "      <td>0.868777</td>\n",
       "      <td>5.1625</td>\n",
       "      <td>-0.0029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.863921</td>\n",
       "      <td>0.862367</td>\n",
       "      <td>0.863921</td>\n",
       "      <td>0.862864</td>\n",
       "      <td>0.7557</td>\n",
       "      <td>-0.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.840800</td>\n",
       "      <td>0.840408</td>\n",
       "      <td>0.840800</td>\n",
       "      <td>0.840380</td>\n",
       "      <td>0.1659</td>\n",
       "      <td>0.1591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.793593</td>\n",
       "      <td>0.790631</td>\n",
       "      <td>0.793593</td>\n",
       "      <td>0.790766</td>\n",
       "      <td>0.2451</td>\n",
       "      <td>0.0574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.775530</td>\n",
       "      <td>0.770976</td>\n",
       "      <td>0.775530</td>\n",
       "      <td>0.769140</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>-0.0024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1-Score  \\\n",
       "7              XGBoost  0.907274   0.907043  0.907274  0.907052   \n",
       "9             CatBoost  0.906069   0.905557  0.906069  0.905767   \n",
       "8             LightGBM  0.905106   0.904767  0.905106  0.904859   \n",
       "2        Random Forest  0.903661   0.902954  0.903661  0.903131   \n",
       "4            SVM (RBF)  0.883189   0.882230  0.883189  0.882603   \n",
       "3         SVM (Linear)  0.869701   0.868421  0.869701  0.868777   \n",
       "0  Logistic Regression  0.863921   0.862367  0.863921  0.862864   \n",
       "1        Decision Tree  0.840800   0.840408  0.840800  0.840380   \n",
       "6                  KNN  0.793593   0.790631  0.793593  0.790766   \n",
       "5          Naive Bayes  0.775530   0.770976  0.775530  0.769140   \n",
       "\n",
       "   Train Time (s)  Overfitting  \n",
       "7          2.4346       0.0769  \n",
       "9         35.4323       0.0483  \n",
       "8          4.7564       0.0711  \n",
       "2          3.8831       0.0962  \n",
       "4          5.1034       0.0137  \n",
       "3          5.1625      -0.0029  \n",
       "0          0.7557      -0.0013  \n",
       "1          0.1659       0.1591  \n",
       "6          0.2451       0.0574  \n",
       "5          0.0260      -0.0024  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_benchmarks(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. TRY CUSTOM MANUAL PIPELINES\n",
    "As seen in benchmarking, XGBoost and Logistic Regression are the best performing models.\n",
    "Now we will try to create a custom pipeline for each of them and see if we can get better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_pipelines = {\n",
    "    'XGBoost (Ajustado)': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', XGBClassifier(\n",
    "            n_estimators=150,\n",
    "            max_depth=4,\n",
    "            learning_rate=0.07,\n",
    "            subsample=0.9,\n",
    "            colsample_bytree=0.9,\n",
    "            reg_alpha=0.5,\n",
    "            reg_lambda=0.7,\n",
    "            use_label_encoder=False,\n",
    "            eval_metric='mlogloss',\n",
    "            random_state=42\n",
    "        ))\n",
    "    ]),\n",
    "\n",
    "    'Logistic Regression (Ajustado)': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', LogisticRegression(\n",
    "            C= 20.0,  # <--- Aumentado desde 1.0 para reducir la regularización\n",
    "            penalty='l2',\n",
    "            class_weight='balanced',\n",
    "            max_iter=1000,\n",
    "            solver='lbfgs',\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fernando\\VSC\\python\\dev\\p7-1\\multi-class_prediction_obesity_risk\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:26:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+--------------------+--------------------+--------------------+--------------------+----------------+-------------+\n",
      "|             Model              |      Accuracy      |     Precision      |       Recall       |      F1-Score      | Train Time (s) | Overfitting |\n",
      "+--------------------------------+--------------------+--------------------+--------------------+--------------------+----------------+-------------+\n",
      "|       XGBoost (Ajustado)       | 0.9053468208092486 | 0.9048472242502588 | 0.9053468208092486 | 0.9049623394462658 |     5.4682     |   0.0097    |\n",
      "| Logistic Regression (Ajustado) | 0.8639210019267822 | 0.8639142688637425 | 0.8639210019267822 | 0.8633476011203041 |     0.7708     |   0.0002    |\n",
      "+--------------------------------+--------------------+--------------------+--------------------+--------------------+----------------+-------------+\n"
     ]
    }
   ],
   "source": [
    "results_df = custom_ml_benchmarks(X, y, models_dict=custom_pipelines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost seems to be the best performing model, so we will try to create a custom pipeline for it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. XGBOOST CUSTOM PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-21 13:59:19,853] A new study created in memory with name: no-name-82b8634a-f0c0-460e-a241-fe3cbd1d352a\n",
      "[I 2025-05-21 13:59:29,511] Trial 0 finished with value: 0.9007049882912807 and parameters: {'n_estimators': 211, 'max_depth': 9, 'learning_rate': 0.07399121925637306, 'subsample': 0.9058122997069449, 'colsample_bytree': 0.8100488489552895, 'gamma': 1.8003221785109669, 'min_child_weight': 9}. Best is trial 0 with value: 0.9007049882912807.\n",
      "[I 2025-05-21 13:59:39,094] Trial 1 finished with value: 0.9053019281303364 and parameters: {'n_estimators': 295, 'max_depth': 3, 'learning_rate': 0.18983693315245503, 'subsample': 0.7935140258818527, 'colsample_bytree': 0.7360484533439278, 'gamma': 0.6132051992890641, 'min_child_weight': 9}. Best is trial 1 with value: 0.9053019281303364.\n",
      "[I 2025-05-21 13:59:41,337] Trial 2 finished with value: 0.9008526024331038 and parameters: {'n_estimators': 67, 'max_depth': 11, 'learning_rate': 0.2244016875576874, 'subsample': 0.6282429965597576, 'colsample_bytree': 0.7687242427028519, 'gamma': 1.9975592987247481, 'min_child_weight': 10}. Best is trial 1 with value: 0.9053019281303364.\n",
      "[I 2025-05-21 13:59:48,918] Trial 3 finished with value: 0.8965594576515388 and parameters: {'n_estimators': 291, 'max_depth': 10, 'learning_rate': 0.10692154827174523, 'subsample': 0.9529679588642066, 'colsample_bytree': 0.9076574197673966, 'gamma': 4.863850482730511, 'min_child_weight': 1}. Best is trial 1 with value: 0.9053019281303364.\n",
      "[I 2025-05-21 13:59:55,649] Trial 4 finished with value: 0.9041102685546116 and parameters: {'n_estimators': 133, 'max_depth': 9, 'learning_rate': 0.09281942441316342, 'subsample': 0.6965247591837553, 'colsample_bytree': 0.6541534560767364, 'gamma': 0.5982902262832218, 'min_child_weight': 6}. Best is trial 1 with value: 0.9053019281303364.\n",
      "[I 2025-05-21 14:00:05,067] Trial 5 finished with value: 0.8966902004047412 and parameters: {'n_estimators': 281, 'max_depth': 8, 'learning_rate': 0.03370349023055612, 'subsample': 0.712027015957363, 'colsample_bytree': 0.5485123593162005, 'gamma': 4.900376094724842, 'min_child_weight': 5}. Best is trial 1 with value: 0.9053019281303364.\n",
      "[I 2025-05-21 14:00:09,464] Trial 6 finished with value: 0.9002948916344402 and parameters: {'n_estimators': 163, 'max_depth': 9, 'learning_rate': 0.22576560238510068, 'subsample': 0.6482457507523329, 'colsample_bytree': 0.6161536285057647, 'gamma': 2.518080138472424, 'min_child_weight': 6}. Best is trial 1 with value: 0.9053019281303364.\n",
      "[I 2025-05-21 14:00:13,690] Trial 7 finished with value: 0.897838951148889 and parameters: {'n_estimators': 154, 'max_depth': 8, 'learning_rate': 0.2794790315637475, 'subsample': 0.9960524396499895, 'colsample_bytree': 0.8355496411551391, 'gamma': 3.18843347572968, 'min_child_weight': 4}. Best is trial 1 with value: 0.9053019281303364.\n",
      "[I 2025-05-21 14:00:17,474] Trial 8 finished with value: 0.8995654203340372 and parameters: {'n_estimators': 157, 'max_depth': 6, 'learning_rate': 0.2695415358483677, 'subsample': 0.8457248486751363, 'colsample_bytree': 0.6961386574242779, 'gamma': 2.5412433564099146, 'min_child_weight': 1}. Best is trial 1 with value: 0.9053019281303364.\n",
      "[I 2025-05-21 14:00:22,116] Trial 9 finished with value: 0.8979862996313656 and parameters: {'n_estimators': 115, 'max_depth': 7, 'learning_rate': 0.032538747660465175, 'subsample': 0.7608954786717991, 'colsample_bytree': 0.728208498881332, 'gamma': 1.4327720935637078, 'min_child_weight': 8}. Best is trial 1 with value: 0.9053019281303364.\n",
      "[I 2025-05-21 14:00:30,360] Trial 10 finished with value: 0.9036720155915807 and parameters: {'n_estimators': 225, 'max_depth': 3, 'learning_rate': 0.16232507960387868, 'subsample': 0.5448417480390833, 'colsample_bytree': 0.9589394569133838, 'gamma': 0.20030093584909991, 'min_child_weight': 8}. Best is trial 1 with value: 0.9053019281303364.\n",
      "[I 2025-05-21 14:00:34,316] Trial 11 finished with value: 0.9001696274861591 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.15274628277002608, 'subsample': 0.7943061165371716, 'colsample_bytree': 0.6451416383615083, 'gamma': 0.09651836477112408, 'min_child_weight': 7}. Best is trial 1 with value: 0.9053019281303364.\n",
      "[I 2025-05-21 14:00:40,911] Trial 12 finished with value: 0.9042468632624492 and parameters: {'n_estimators': 233, 'max_depth': 5, 'learning_rate': 0.1453255481692174, 'subsample': 0.6793075202953289, 'colsample_bytree': 0.5277468502489902, 'gamma': 0.9412715424640994, 'min_child_weight': 3}. Best is trial 1 with value: 0.9053019281303364.\n",
      "[I 2025-05-21 14:00:47,572] Trial 13 finished with value: 0.9043600017539464 and parameters: {'n_estimators': 247, 'max_depth': 5, 'learning_rate': 0.16558616315924946, 'subsample': 0.5230281031765276, 'colsample_bytree': 0.5694955116918992, 'gamma': 0.9781062116013592, 'min_child_weight': 3}. Best is trial 1 with value: 0.9053019281303364.\n",
      "[I 2025-05-21 14:00:54,239] Trial 14 finished with value: 0.9032608815078843 and parameters: {'n_estimators': 259, 'max_depth': 5, 'learning_rate': 0.20170197305159093, 'subsample': 0.5445585578873129, 'colsample_bytree': 0.5799162829491448, 'gamma': 1.1900490540684805, 'min_child_weight': 2}. Best is trial 1 with value: 0.9053019281303364.\n",
      "[I 2025-05-21 14:00:58,782] Trial 15 finished with value: 0.897941265725933 and parameters: {'n_estimators': 197, 'max_depth': 4, 'learning_rate': 0.18778737461323805, 'subsample': 0.8134417057128243, 'colsample_bytree': 0.5007540081680165, 'gamma': 3.495785673366542, 'min_child_weight': 4}. Best is trial 1 with value: 0.9053019281303364.\n",
      "[I 2025-05-21 14:01:06,869] Trial 16 finished with value: 0.9038307276437086 and parameters: {'n_estimators': 260, 'max_depth': 5, 'learning_rate': 0.12493404757386857, 'subsample': 0.505198058313628, 'colsample_bytree': 0.8996029078795893, 'gamma': 0.7085747847223851, 'min_child_weight': 10}. Best is trial 1 with value: 0.9053019281303364.\n",
      "[I 2025-05-21 14:01:13,990] Trial 17 finished with value: 0.9011506991598747 and parameters: {'n_estimators': 297, 'max_depth': 4, 'learning_rate': 0.24630477109648785, 'subsample': 0.8725900026082618, 'colsample_bytree': 0.6863616963644378, 'gamma': 1.7186291916660636, 'min_child_weight': 4}. Best is trial 1 with value: 0.9053019281303364.\n",
      "[I 2025-05-21 14:01:22,360] Trial 18 finished with value: 0.9037557165679472 and parameters: {'n_estimators': 255, 'max_depth': 3, 'learning_rate': 0.1832271176430499, 'subsample': 0.593304365907216, 'colsample_bytree': 0.5915195358400591, 'gamma': 0.005942153803657035, 'min_child_weight': 3}. Best is trial 1 with value: 0.9053019281303364.\n",
      "[I 2025-05-21 14:01:29,486] Trial 19 finished with value: 0.898298794917947 and parameters: {'n_estimators': 242, 'max_depth': 6, 'learning_rate': 0.21171027520723962, 'subsample': 0.769797686611672, 'colsample_bytree': 0.7591976605450693, 'gamma': 3.1728147405806726, 'min_child_weight': 7}. Best is trial 1 with value: 0.9053019281303364.\n",
      "[I 2025-05-21 14:01:35,665] Trial 20 finished with value: 0.9019319399416128 and parameters: {'n_estimators': 187, 'max_depth': 12, 'learning_rate': 0.2490393315900506, 'subsample': 0.7414155348797821, 'colsample_bytree': 0.8168134315254203, 'gamma': 0.6021594168380453, 'min_child_weight': 5}. Best is trial 1 with value: 0.9053019281303364.\n",
      "[I 2025-05-21 14:01:42,477] Trial 21 finished with value: 0.9041151003845188 and parameters: {'n_estimators': 230, 'max_depth': 5, 'learning_rate': 0.14585342493972392, 'subsample': 0.6681354381132519, 'colsample_bytree': 0.5146281211247224, 'gamma': 1.0682521391832007, 'min_child_weight': 3}. Best is trial 1 with value: 0.9053019281303364.\n",
      "[I 2025-05-21 14:01:50,393] Trial 22 finished with value: 0.9043024791379457 and parameters: {'n_estimators': 267, 'max_depth': 4, 'learning_rate': 0.17123280828161339, 'subsample': 0.5956571982568594, 'colsample_bytree': 0.5708837420106071, 'gamma': 0.9490820523007041, 'min_child_weight': 2}. Best is trial 1 with value: 0.9053019281303364.\n",
      "[I 2025-05-21 14:01:58,388] Trial 23 finished with value: 0.903965503612576 and parameters: {'n_estimators': 276, 'max_depth': 4, 'learning_rate': 0.17049202190950377, 'subsample': 0.5957649215242694, 'colsample_bytree': 0.5724494013224869, 'gamma': 1.3179635961178562, 'min_child_weight': 2}. Best is trial 1 with value: 0.9053019281303364.\n",
      "[I 2025-05-21 14:02:09,930] Trial 24 finished with value: 0.9041010654206229 and parameters: {'n_estimators': 272, 'max_depth': 6, 'learning_rate': 0.11498015154096111, 'subsample': 0.5020462086182509, 'colsample_bytree': 0.6181857622207659, 'gamma': 0.5922360026776311, 'min_child_weight': 2}. Best is trial 1 with value: 0.9053019281303364.\n",
      "[I 2025-05-21 14:02:19,883] Trial 25 finished with value: 0.9023416178941684 and parameters: {'n_estimators': 296, 'max_depth': 4, 'learning_rate': 0.18926916436736907, 'subsample': 0.5664323142902336, 'colsample_bytree': 0.7041590347636932, 'gamma': 2.1029936014884107, 'min_child_weight': 1}. Best is trial 1 with value: 0.9053019281303364.\n",
      "[I 2025-05-21 14:02:27,197] Trial 26 finished with value: 0.9020356925634122 and parameters: {'n_estimators': 211, 'max_depth': 3, 'learning_rate': 0.13015222386219333, 'subsample': 0.6064792127888271, 'colsample_bytree': 0.6384190280806321, 'gamma': 1.6026839672931614, 'min_child_weight': 3}. Best is trial 1 with value: 0.9053019281303364.\n",
      "[I 2025-05-21 14:02:34,183] Trial 27 finished with value: 0.8956269517702969 and parameters: {'n_estimators': 249, 'max_depth': 7, 'learning_rate': 0.06844813540278931, 'subsample': 0.7234978960095061, 'colsample_bytree': 0.6774800152343877, 'gamma': 4.226664732957873, 'min_child_weight': 9}. Best is trial 1 with value: 0.9053019281303364.\n",
      "[I 2025-05-21 14:02:41,325] Trial 28 finished with value: 0.9014524083258109 and parameters: {'n_estimators': 271, 'max_depth': 4, 'learning_rate': 0.17070764506064187, 'subsample': 0.5405100360334815, 'colsample_bytree': 0.5508143885751573, 'gamma': 2.2089796641430457, 'min_child_weight': 2}. Best is trial 1 with value: 0.9053019281303364.\n",
      "[I 2025-05-21 14:02:48,231] Trial 29 finished with value: 0.9037915036118176 and parameters: {'n_estimators': 213, 'max_depth': 3, 'learning_rate': 0.2993976319074136, 'subsample': 0.9162617695347768, 'colsample_bytree': 0.8561241086468809, 'gamma': 0.3573333180503525, 'min_child_weight': 5}. Best is trial 1 with value: 0.9053019281303364.\n",
      "c:\\Users\\Fernando\\VSC\\python\\dev\\p7-1\\multi-class_prediction_obesity_risk\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [14:02:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------+-------------------+-------------------+--------------------+----------------+-------------+\n",
      "|      Model       |     Accuracy      |     Precision     |      Recall       |      F1-Score      | Train Time (s) | Overfitting |\n",
      "+------------------+-------------------+-------------------+-------------------+--------------------+----------------+-------------+\n",
      "| XGBoost + Optuna | 0.911849710982659 | 0.911707052980141 | 0.911849710982659 | 0.9115821436962183 |     4.1328     |   0.0185    |\n",
      "+------------------+-------------------+-------------------+-------------------+--------------------+----------------+-------------+\n"
     ]
    }
   ],
   "source": [
    "optuna_pipeline, optuna_study = optimize_xgboost(X, y, n_trials=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. TRAIN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = optuna_pipeline.predict(X)\n",
    "y_proba = optuna_pipeline.predict_proba(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. EXPORT MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔️ Modelo guardado en: c:\\Users\\Fernando\\VSC\\python\\dev\\p7-1\\multi-class_prediction_obesity_risk\\data\\modeling\\pkl\\xgboost_optuna_pipeline.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "current_dir = os.getcwd()\n",
    "model_pkl_filename = \"xgboost_optuna_pipeline.pkl\"\n",
    "model_pkl_path = os.path.join(current_dir, \"pkl\",model_pkl_filename)\n",
    "\n",
    "joblib.dump(optuna_pipeline, model_pkl_path)\n",
    "\n",
    "print(f\"✔️ Modelo guardado en: {model_pkl_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
